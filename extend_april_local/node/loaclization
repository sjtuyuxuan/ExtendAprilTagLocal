#!/usr/bin/env python
from array import array
from pickletools import float8
import rospy
import apriltag
import numpy as np
from cv_bridge import CvBridge, CvBridgeError
from std_msgs.msg import String
from sensor_msgs.msg import Image
from geometry_msgs.msg import PoseWithCovarianceStamped
import cv2
import yaml


class image_processor:
  def __init__(self, config):
    self.bridge = CvBridge()
    self.image_sub = rospy.Subscriber(config["ImageTopic"],Image, self.callback)
    self.pub = rospy.Publisher(config["PosePublishTopic"], PoseWithCovarianceStamped, queue_size=10)
    # april tag
    options = apriltag.DetectorOptions(families="tag16h5",nthreads=1)
    self.detector = apriltag.Detector(options)
    self.config = config
    self.extrinsics = {}

  def callback(self,data):
    try:
      image = self.bridge.imgmsg_to_cv2(data, "bgr8")
      gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
      results = self.detector.detect(gray)
      views = {}
      for r in results:
          if r.tag_id not in self.config["GenTags"]:
              continue
          obj_points = []
          image_points = []
          (ptA, ptB, ptC, ptD) = r.corners
          ptB = [int(ptB[0]), int(ptB[1])]
          ptC = [int(ptC[0]), int(ptC[1])]
          ptD = [int(ptD[0]), int(ptD[1])]
          ptA = [int(ptA[0]), int(ptA[1])]
          ab = np.array([ptB[0] - ptA[0], ptB[1] - ptA[1]])
          bc = np.array([ptB[0] - ptC[0], ptB[1] - ptC[1]])
          center_point = np.array([r.center[0], r.center[1]])
          ratio = np.linalg.norm(ab) / np.linalg.norm(bc)
          angle_cos = np.dot(ab, bc) / (np.linalg.norm(ab) * np.linalg.norm(bc))
          if 0.666 < ratio < 1.5 and abs(angle_cos) < 0.5:
              # draw the center (x, y)-coordinates of the AprilTag
              point = np.array([ptA, ptB, ptC, ptD], np.int32)
              image_points.append(ptA)
              image_points.append(ptB)
              image_points.append(ptC)
              image_points.append(ptD)
              obj_points.append((np.array(self.config[r.tag_id]["Extrinsic"]) @ np.array([-self.config[r.tag_id]["Size"]/2, self.config[r.tag_id]["Size"]/2, 0, 1]))[0:3])
              obj_points.append((np.array(self.config[r.tag_id]["Extrinsic"]) @ np.array([self.config[r.tag_id]["Size"]/2, self.config[r.tag_id]["Size"]/2, 0, 1]))[0:3])
              obj_points.append((np.array(self.config[r.tag_id]["Extrinsic"]) @ np.array([self.config[r.tag_id]["Size"]/2, -self.config[r.tag_id]["Size"]/2, 0, 1]))[0:3])
              obj_points.append((np.array(self.config[r.tag_id]["Extrinsic"]) @ np.array([-self.config[r.tag_id]["Size"]/2, -self.config[r.tag_id]["Size"]/2, 0, 1]))[0:3])
              cv2.polylines(image, [point], True, (0, 255, 0), 3)

              # candidate dot
              for dot in self.config[r.tag_id]["Extand_Dot"]:
                  center = center_point + ab / self.config[r.tag_id]["Size"] * dot[0] + bc / self.config[r.tag_id]["Size"] * dot[1]
                  cen_int = np.array([int(center[0]), int(center[1])])
                  size = int(2 * (np.linalg.norm(ab) + np.linalg.norm(bc)) / self.config[r.tag_id]["Size"] * dot[2])
                  if cen_int[0] + size < image.shape[1] and 0 < cen_int[0] - size and cen_int[1] + size < image.shape[0] and 0 < cen_int[1] - size:
                      cv2.circle(image, [int(center[0]), int(center[1])], int(size), (255, 150, 150), 2)
                      mean = np.mean(gray[cen_int[1]-size:cen_int[1]+size, cen_int[0]-size:cen_int[0]+size])
                      valid_point = []
                      for i in range(cen_int[0]-size,cen_int[0]+size,1):
                          for j in range(cen_int[1]-size,cen_int[1]+size,1):
                              if gray[j][i] < mean / 1.2:
                                  valid_point.append([i, j])

                      if len(valid_point) > 1:
                          c = np.mean(np.array(valid_point), axis=0)
                          cv2.circle(image, [int(c[0]), int(c[1])], 3, (0, 0, 200), -1)
                          image_points.append([c[0], c[1]])
                          obj_points.append((np.array(self.config[r.tag_id]["Extrinsic"]) @ np.array([dot[0], dot[1], 0, 1]))[0:3])
              intrinsic = np.reshape(np.array(self.config["ImageIntrinsic"]), (3, 3))
              if len(obj_points) > 4:
                  (_, r_, t) = cv2.solvePnP(np.array(obj_points),np.array(image_points), intrinsic, distCoeffs=np.zeros((5, 1), dtype=np.float32))
              # print(r)
                  (R, _) = cv2.Rodrigues(r_)
                  t_wc = np.linalg.inv(R) @ (-t)
                  if r.tag_id == 0:
                      print(t_wc)
                      pass
                  views[r.tag_id] = [r_, t]
      if 0 in views and len(views) > 1:
          (R_c0, _) = cv2.Rodrigues(views[0][0])
          R_0c = np.linalg.inv(R_c0)
          t_0c = R_0c @ (-views[0][1])
          for view in views:
              (R_ci, _) = cv2.Rodrigues(views[view][0])
              R_0i = R_0c @ R_ci
              (r_0i, _) = cv2.Rodrigues(R_0i)
              t_0i = t_0c + R_0c @ views[view][1]
              if view not in self.extrinsics:
                  self.extrinsics[view] = [1, r_0i, t_0i]
              else:
                  count = self.extrinsics[view][0]
                  r_update = (count * self.extrinsics[view][1] + r_0i) / (1 + count)
                  t_update = (count * self.extrinsics[view][2] + t_0i) / (1 + count)
                  self.extrinsics[view] = [count+1, r_update, t_update]
      else:
          for view in views:
              if view in self.extrinsics:
                  (R_ci, _) = cv2.Rodrigues(views[view][0])
                  R_ic = np.linalg.inv(R_ci)
                  t_ic = R_ic @ (-views[view][1])
                  (R_0i, _) = cv2.Rodrigues(self.extrinsics[view][1])
                  R_0c = R_0i @ R_ic
                  t_0c = self.extrinsics[view][2] + t_ic
                  print(t_ic)
                  break
      cv2.imshow("test", image)
      cv2.waitKey(33)
    except CvBridgeError as e:
      print(e)

def main():
    rospy.init_node("localization")
    fs = open(("config.yaml"),encoding="UTF-8")
    config = yaml.load(fs,Loader=yaml.FullLoader)


    # image_undistort = np.zeros((config["ImageSize"][0], config["ImageSize"][1], 3),dtype=np.uint8)
    image_processor(config)

    rate = rospy.Rate(30)

    # Undistort
    # intrinsic = np.array([[config["ImageIntrinsic"][0], 0., config["ImageIntrinsic"][2]], [0., config["ImageIntrinsic"][1], config["ImageIntrinsic"][3]], [0., 0., 1.]])
    # projection = cv2.getOptimalNewCameraMatrix(intrinsic, np.array(config["ImageDistrotion"]), config["ImageSize"], 0)
    # map1, map2 = cv2.initUndistortRectifyMap(intrinsic, np.array(config["ImageDistrotion"]), np.array([]) ,projection, config["ImageSize"], cv2.CV_32FC1)



    while not rospy.is_shutdown():
        # cv2.remap(image, image_undistort, map1, map2, cv2.INTER_CUBIC)
        # cv2.imshow("test", image)
        # cv2.waitKey(33)
        # results = detector.detect(image_undistort)
        # obj_point = []
        # image_point = []
        # for r in results:
        #     (ptA, ptB, ptC, ptD) = r.corners
        #     ptB = (int(ptB[0]), int(ptB[1]))
        #     ptC = (int(ptC[0]), int(ptC[1]))
        #     ptD = (int(ptD[0]), int(ptD[1]))
        #     ptA = (int(ptA[0]), int(ptA[1]))
        #     # draw the center (x, y)-coordinates of the AprilTag
        #     (cX, cY) = (int(r.center[0]), int(r.center[1]))
        #     image_point.append(ptA)
        #     image_point.append(ptB)
        #     image_point.append(ptC)
        #     image_point.append(ptD)
        #     obj_point.append([-config[0]["Size"]/2, config[0]["Size"]/2, 0])
        #     obj_point.append([config[0]["Size"]/2, config[0]["Size"]/2, 0])
        #     obj_point.append([config[0]["Size"]/2, -config[0]["Size"]/2, 0])
        #     obj_point.append([-config[0]["Size"]/2, -config[0]["Size"]/2, 0])
        # cv2.solvePnP(config)


        rate.sleep()

if __name__ == '__main__':
    main()